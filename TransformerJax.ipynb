{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1hDfjdUMaOO00WyflWO-VCSIQnRvpAOUh",
      "authorship_tag": "ABX9TyPPq7c8TyT/9rQUD6wHumaf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhenyiqi/rawLLM/blob/main/TransformerJax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook follows strictly the paper [\"Attenion is all you need\"](https://arxiv.org/pdf/1706.03762.pdf) (or it intends to do so), althought the architecture has countless variants right now. For different architectures, please refer to other notebooks (coming soon)."
      ],
      "metadata": {
        "id": "p-wWullxkWBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Q611jPYD5jFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "b2QUL3oX5-1c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wPShDzNzouNd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# import torch for getting the data\n",
        "from torch.utils import data\n",
        "from torchvision.datasets import MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logsumexp\n",
        "\n",
        "from jax import grad, jit, vmap\n",
        "# random is used to generate random matrix and manage random keys.\n",
        "from jax import random\n",
        "import jax\n",
        "from flax.training import train_state, checkpoints"
      ],
      "metadata": {
        "id": "JIYsEBneoyKN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install flax --quiet"
      ],
      "metadata": {
        "id": "XBf1OGtN9emw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flax\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "xrtXGOKb8Org"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Optax (Optimizers in JAX)\n",
        "try:\n",
        "    import optax\n",
        "except ModuleNotFoundError: # Install optax if missing\n",
        "    !pip install --quiet optax\n",
        "    import optax"
      ],
      "metadata": {
        "id": "_VNe0GjbxH9R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define constants"
      ],
      "metadata": {
        "id": "gxqXzVOC5hLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng_main = random.PRNGKey(0)"
      ],
      "metadata": {
        "id": "Wll64TI0uZzw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 16\n",
        "# n_targets = 10\n",
        "# num_epochs = 5\n",
        "\n",
        "# layer_sizes = [784, 512, 512, 10]\n",
        "# step_size = 0.01"
      ],
      "metadata": {
        "id": "JbnG56wtr3Bu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Prep"
      ],
      "metadata": {
        "id": "Oreq5dxN5Zd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = random.PRNGKey(42)"
      ],
      "metadata": {
        "id": "P_QThnW_82No"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils for initalizing parameters"
      ],
      "metadata": {
        "id": "qr0cDWZjFi9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7fLenHdm76d",
        "outputId": "dda421aa-4361-418b-f74a-2e9eb80efd33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([ 0, 42], dtype=uint32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from traitlets.traitlets import Tuple\n",
        "\n",
        "# # A helper function to randomly initialize weights and biases\n",
        "# # for a dense neural network layer.\n",
        "# def random_layer_params(input_dim, output_dim, key, scale=1e-2):\n",
        "#   w_key, b_key = random.split(key)\n",
        "#   # random.normal(w_key, (n, m)) generates a random matrix of dimension (n, m)\n",
        "#   return (scale * random.normal(w_key, (output_dim, input_dim)),\n",
        "#           scale * random.normal(b_key, (output_dim,)))\n",
        "\n",
        "# # Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
        "# def init_network_params(sizes, key: ...):\n",
        "#   keys = random.split(key, len(sizes))\n",
        "#   return [random_layer_params(m, n, k)\n",
        "#           for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
      ],
      "metadata": {
        "id": "pu2jrX2z6gQa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core training utils"
      ],
      "metadata": {
        "id": "TmluYmusFnxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Builds the model"
      ],
      "metadata": {
        "id": "fyms2hYhJJrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaled dot-product attention\n",
        "\n",
        "The scaled dot-product attention is calculated as  \n",
        "\n",
        "\n",
        "$$\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "$Q\\in\\mathbb{R}^{T\\times d_k}$, keys $K\\in\\mathbb{R}^{T\\times d_k}$ and values $V\\in\\mathbb{R}^{T\\times d_v}$, where $T$ is the sequence length, and $d_k$ is the hidden dimension. In practice, we can add make all of them tensor of dimension $\\mathbb{R}^{B\\times T \\times d_k}$, where $B$ is batch size."
      ],
      "metadata": {
        "id": "WtrE1KxW_xud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask = None):\n",
        "  \"\"\"Q attend to the K-V pair.\n",
        "\n",
        "  q, k, v are matrices of size (batch_size * ) T * k_q, where, T is the sequence length,\n",
        "  and k_q is the hidden dimension.\n",
        "  We may add dimensions in the front for parallelized computation.\"\"\"\n",
        "  k_q = q.shape[-1]\n",
        "\n",
        "  # attention_logits is of dimension (batch_size * ) T * T\n",
        "  attention_logits = jnp.matmul(q, jnp.swapaxes(k, -1, -2)) / math.sqrt(k_q)\n",
        "  if mask is not None:\n",
        "    attention_logits = jnp.where(mask == 0, -9e15, attention_logits)\n",
        "  attention = nn.softmax(attention_logits)\n",
        "\n",
        "  # values is of dimension (batch_size * ) T * k_q again.\n",
        "  values = jnp.matmul(attention, v)\n",
        "  return values"
      ],
      "metadata": {
        "id": "EWdSeMbyjTzy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test scaled dot-product attention"
      ],
      "metadata": {
        "id": "ZIq04sYX0Ou7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assuming we have a tensor of (batch_size=2, sequence_length=2, k_q=3)\n",
        "q = jnp.array([[[1, 2, 3], [4, 5, 6]], [[2, 2, 2], [3, 3, 3]]])\n",
        "v = q.copy()\n",
        "k = q.copy()"
      ],
      "metadata": {
        "id": "8NX52U_Z0SI9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.shape == (2, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTsapfnwAcDB",
        "outputId": "16217479-70c4-4516-f962-a25d3d457a03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = scaled_dot_product_attention(q, k, v)\n",
        "# final values should have the same dimension\n",
        "values.shape == (2, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efml_OSbAPbQ",
        "outputId": "5f1d0752-100b-47dd-83b9-3f9fb62a17d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now assuming that we have a tensor of (num_heads=3, batch_size=2, sequence_length=2, k_q = 3)\n",
        "q = jnp.array([\n",
        "    [[[1, 2, 3], [4, 5, 6]], [[2, 2, 2], [3, 3, 3]]],\n",
        "    [[[1, 2, 3], [4, 5, 6]], [[2, 2, 2], [3, 3, 3]]],\n",
        "    [[[1, 2, 3], [4, 5, 6]], [[2, 2, 2], [3, 3, 3]]],\n",
        "    [[[1, 2, 3], [4, 5, 6]], [[2, 2, 2], [3, 3, 3]]],\n",
        "])\n",
        "k = q.copy()\n",
        "v = q.copy()\n",
        "q.shape == (4, 2, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Eii3RkAhvm",
        "outputId": "2d6ee90c-d69d-41f6-b14b-02eb45cc14d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = scaled_dot_product_attention(q, k, v)"
      ],
      "metadata": {
        "id": "7cg4z8NKAfBy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape == (4, 2, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jllODzH6BD3T",
        "outputId": "7e545d99-9c07-442c-b99d-7f824e48ecf2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MLP Layer"
      ],
      "metadata": {
        "id": "znJ9sOulu9C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x: jnp.ndarray):\n",
        "  \"\"\"Relu operation on a matrix\"\"\"\n",
        "  return jnp.maximum(0, x)\n",
        "\n",
        "class MLPLayer(nn.Module):\n",
        "  \"\"\"A Multi-layer perceptor + a layer norm with skipped add.\"\"\"\n",
        "  input_dim: int\n",
        "  hidden_dim: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.layer_norm = nn.LayerNorm()\n",
        "    self.input_layer = nn.Dense(self.hidden_dim, use_bias=False)\n",
        "    self.output_layer = nn.Dense(self.input_dim, use_bias=False)\n",
        "\n",
        "  def __call__(self, input):\n",
        "    x = input\n",
        "    x = self.input_layer(x)\n",
        "    x = self.output_layer(x)\n",
        "    x = self.layer_norm(x + input)\n",
        "    return x"
      ],
      "metadata": {
        "id": "hRCXuxAVvAQ4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MultiHeadAttention Layer"
      ],
      "metadata": {
        "id": "WIsPySahvESk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttnLayer(nn.Module):\n",
        "  \"\"\"A Multi-Head attention layer.\n",
        "\n",
        "  This is the most explicit translation of the paper.\n",
        "  \"\"\"\n",
        "  output_dim: int\n",
        "  num_heads: int  # also notated as h.\n",
        "\n",
        "  def setup(self):\n",
        "    if self.output_dim % (self.num_heads) != 0:\n",
        "      raise ValueError(\n",
        "          'output_dim for a MultiHeadAttnLayer must be multiples of '\n",
        "          'num_heads.')\n",
        "\n",
        "    # Projection layers:\n",
        "    # output dimension k_q of each connected layer is\n",
        "    # (total output dimension) / num_heads\n",
        "    # there are 3 * num_heads of such layers, because for each head,\n",
        "    # we need to apply such layer to q, k and v matrices. The q, k, v matrices\n",
        "    # are of dimension (batch_size, sequence_length, embed_dim), therefore the\n",
        "    # the weight matrix of each layer needs to be (embed_dim, k_v). And there\n",
        "    # are 3 * num_heads of them.\n",
        "\n",
        "    # 1) [0, num_heads) are applied to q\n",
        "    # 2) [num_heads, num_heads * 2) are applied to k\n",
        "    # 3) [2 * num_heads, 3 * num_heads) are applied to v\n",
        "    self.qkv_projs = [nn.Dense(self.output_dim // self.num_heads,\n",
        "                               kernel_init=nn.initializers.xavier_uniform(),  # Weights with Xavier uniform init\n",
        "                               bias_init=nn.initializers.zeros) for _ in range(3 * self.num_heads)]\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm()\n",
        "\n",
        "\n",
        "  def __call__(self,\n",
        "               x, y,\n",
        "               mask: jnp.ndarray | None = None):\n",
        "    batch_size, sequence_length, embed_dim = x.shape  # embed_dim is also d_{model}\n",
        "\n",
        "    # after the code block below, the dimension of Q, K, V becomes\n",
        "    # [batch_size, T, output_dim / (3 * num_heads), 3]\n",
        "    # q, k and v are matrices of dimension (num_heads, batch_size, T, k_q).\n",
        "    # num_heads is the new dimension after stacking.\n",
        "    q = jnp.stack(tuple(self.qkv_projs[i](x) for i in range(self.num_heads)))\n",
        "    k = jnp.stack(tuple(self.qkv_projs[i](y) for i in range(self.num_heads, 2 * self.num_heads)))\n",
        "    v = jnp.stack(tuple(self.qkv_projs[i](y) for i in range(2 * self.num_heads, 3 * self.num_heads)))\n",
        "\n",
        "    # values will be a tensor of dimension (num_heads, batch_size, T, k_q)\n",
        "    values = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "\n",
        "    # concatenate the values of different heads\n",
        "    # values will be a tensor of dimension (batch_size, T, embed_dim)\n",
        "    values = jnp.moveaxis(values, 0, -1)\n",
        "    values = values.reshape(batch_size, sequence_length, -1)\n",
        "\n",
        "    # skip-add operation\n",
        "    values = self.layer_norm(values + x)\n",
        "\n",
        "    return values"
      ],
      "metadata": {
        "id": "K6RaTt0BvJo5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test MultiHeadAttention Layer"
      ],
      "metadata": {
        "id": "lhSN4KH0KSaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The three dimensions correspond to (batch_size, sequence_length, input_dim/output_dim)\n",
        "x = random.normal(random.PRNGKey(42), (3, 128, 512))\n",
        "y = random.normal(random.PRNGKey(0), (3, 128, 512))"
      ],
      "metadata": {
        "id": "PHYLG0tUKV8x"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttnLayer(output_dim=512, num_heads=8)"
      ],
      "metadata": {
        "id": "mDltes5DKfra"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = multi_head_attention.init(random.PRNGKey(42), x, x)"
      ],
      "metadata": {
        "id": "kpJN3YZSKr7j"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fACTn_GYUX1B",
        "outputId": "40843544-06ca-4333-e3bc-ee5da5b6d2da"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'layer_norm': {'bias': (512,), 'scale': (512,)},\n",
              "  'qkv_projs_0': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_1': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_10': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_11': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_12': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_13': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_14': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_15': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_16': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_17': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_18': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_19': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_2': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_20': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_21': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_22': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_23': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_3': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_4': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_5': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_6': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_7': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_8': {'bias': (64,), 'kernel': (512, 64)},\n",
              "  'qkv_projs_9': {'bias': (64,), 'kernel': (512, 64)}}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = multi_head_attention.apply(params, x, x)"
      ],
      "metadata": {
        "id": "VpNBGSmpU0x7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape == x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv22S-7uVTlR",
        "outputId": "90b5d618-8977-4b8e-a4d5-4e700a6e5863"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder Block"
      ],
      "metadata": {
        "id": "rUsvyE79vLYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  \"\"\"Encoder block that contains multi-head self-attention layer and MLP.\"\"\"\n",
        "  input_dim: int\n",
        "  num_heads: int\n",
        "  def setup(self):\n",
        "    self.multi_head_attn_layer = MultiHeadAttnLayer(output_dim=self.input_dim,\n",
        "                                                    num_heads=self.num_heads)\n",
        "\n",
        "    self.mlp_layer = MLPLayer(input_dim=self.input_dim, hidden_dim=4 * self.input_dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    values = self.multi_head_attn_layer(x, x)\n",
        "    output = self.mlp_layer(values)\n",
        "    return output"
      ],
      "metadata": {
        "id": "xRB2OSTwvN0G"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "ilR5tQPyvO7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  \"\"\"Encoder that repeats the Encoder layer N times.\"\"\"\n",
        "  num_layers: int # N\n",
        "  input_dim: int\n",
        "  num_heads: int\n",
        "\n",
        "  def setup(self):\n",
        "    # TODO: add the embedding layer\n",
        "    self.encoder_blocks = [\n",
        "        EncoderBlock(input_dim=self.input_dim, num_heads=self.num_heads) for _ in range(self.num_layers)]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # TODO: add the embedding layer\n",
        "    for encoder_block in self.encoder_blocks:\n",
        "      x = encoder_block(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5zuVB5IDvQsT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder Block"
      ],
      "metadata": {
        "id": "BdS8txoYvSI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  \"\"\"Decoder block that contains Multi-head attention layer, cross-attention layer and MLP.\"\"\"\n",
        "  input_dim: int\n",
        "  num_heads: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.multi_head_attn_layer = MultiHeadAttnLayer(\n",
        "        input_dim=self.input_dim, num_heads=self.num_heads)\n",
        "    self.cross_attn_layer = MultiHeadAttnLayer(input_dim=self.input_dim,\n",
        "                                               num_heads=self.num_heads)\n",
        "    self.mlp_layer = MLPLayer(input_dim=self.input_dim, hidden_dim=self.input_dim * 4)\n",
        "\n",
        "\n",
        "  def __call__(self, y, x):\n",
        "    \"\"\"y is either the initial input of decoder or output of last DecoderBlock.\n",
        "    x is the output from the Encoder.\"\"\"\n",
        "    y = self.multi_head_attn_layer(y, y)\n",
        "    y = self.cross_attn_layer(y, x)\n",
        "    y = self.mlp_layer(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "yYHmPTuivUCE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "K_MVZ1XJvWuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  num_layers: int\n",
        "  input_dim: int\n",
        "  num_heads: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.decoder_block = DecoderBlock(input_dim=self.input_dim,\n",
        "                                      num_heads=self.num_heads)\n",
        "    self.projection = nn.Dense(features=self.input_dim)\n",
        "    self.softmax = nn.softmax(features=self.input_dim)\n",
        "\n",
        "  def __call__(self, x, y, is_train: bool = False):\n",
        "    for i in range(self.num_layers):\n",
        "      y = self.decoder_block(y, x)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "ds3KjIRzvYTz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "94rD6oKHvZqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  num_encoder_block: int\n",
        "  num_decoder_block: int\n",
        "  # input_dim is not sequence length, it's the embedding dimension\n",
        "  input_dim: int\n",
        "  num_heads: int\n",
        "  def setup(self):\n",
        "    self.encoder = Encoder(num_layers=self.num_encoder_block,\n",
        "                           input_dim=self.input_dim,\n",
        "                           num_heads=self.num_heads)\n",
        "    self.decoder = Decoder(num_layers=self.num_decoder_block,\n",
        "                           input_dim=self.input_dim,\n",
        "                           num_heads=self.num_heads)\n",
        "\n",
        "  def __call__(self, x, y):\n",
        "    x = self.encoder(x)\n",
        "    output = self.decoder(x, y)\n",
        "    return output"
      ],
      "metadata": {
        "id": "GRORNEdQJI8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Transformer"
      ],
      "metadata": {
        "id": "H4864QROqmhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_encoder_block=2,\n",
        "                          num_decoder_block=3,\n",
        "                          input_dim=10,\n",
        "                          num_heads=2)"
      ],
      "metadata": {
        "id": "lemOR6C975uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a dummy example as the input to initialize the linen module.\n"
      ],
      "metadata": {
        "id": "jeAY0aMyuQk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng_params, rng_x, rng_y = random.split(rng_main, 3)"
      ],
      "metadata": {
        "id": "lPRSEmKdCxjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_x = random.normal(rng_x, (64, 20, 10))\n",
        "example_y = random.normal(rng_y, (64, 20, 10))"
      ],
      "metadata": {
        "id": "lBslqalgYYCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize the linen module"
      ],
      "metadata": {
        "id": "v18giwiqC8vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = transformer.init(random.PRNGKey(0), example_x, example_y)['params']"
      ],
      "metadata": {
        "id": "E7lyZVZU8Dn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Try applying the model on the dummy input and see the output format"
      ],
      "metadata": {
        "id": "d8fWM60TDAIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = transformer.apply({'params': params}, example_x, example_y)\n",
        "print('Out', out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTuKv1sttqAe",
        "outputId": "5058ecd9-ba75-4b0c-a9d6-9980696e837e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out (64, 20, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wfZda_8t-jh",
        "outputId": "5c67c9f0-0156-404f-f036-350d2e5b200c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[-0.81314814,  1.1046953 ,  0.4776487 , ...,  1.2827947 ,\n",
              "               -0.8177259 ,  0.68436754],\n",
              "              [-0.9457575 ,  1.0223197 ,  0.44467473, ...,  1.2053069 ,\n",
              "               -0.87547475,  0.7679628 ],\n",
              "              [ 0.8291353 , -1.0935264 , -0.3079091 , ..., -1.2200329 ,\n",
              "                0.7818424 , -0.8695053 ],\n",
              "              ...,\n",
              "              [-0.94948304,  1.0248268 ,  0.45207748, ...,  1.207757  ,\n",
              "               -0.868755  ,  0.7732253 ],\n",
              "              [ 0.72673786, -1.1195886 , -0.19017659, ..., -1.2199332 ,\n",
              "                0.7187557 , -0.9032288 ],\n",
              "              [-0.9352995 ,  1.0279328 ,  0.44403443, ...,  1.2102603 ,\n",
              "               -0.87217087,  0.7617321 ]],\n",
              "\n",
              "             [[-0.63446015,  1.1582543 ,  0.1800934 , ...,  1.2679591 ,\n",
              "               -0.7362134 ,  0.84023964],\n",
              "              [ 0.76549387, -1.1043112 , -0.28653726, ..., -1.2490824 ,\n",
              "                0.7787767 , -0.8253995 ],\n",
              "              [-0.5244601 ,  1.173768  ,  0.05919825, ...,  1.260003  ,\n",
              "               -0.70110697,  0.8402413 ],\n",
              "              ...,\n",
              "              [-0.5943236 ,  1.164451  ,  0.13514261, ...,  1.2644212 ,\n",
              "               -0.7364697 ,  0.8345025 ],\n",
              "              [-0.46722734,  1.1766708 , -0.03807398, ...,  1.2341907 ,\n",
              "               -0.6655057 ,  0.87532103],\n",
              "              [-1.1194671 ,  0.9863867 ,  0.6058963 , ...,  1.2141169 ,\n",
              "               -0.88737863,  0.8742763 ]],\n",
              "\n",
              "             [[ 0.6303829 , -1.1702802 , -0.17349073, ..., -1.2661736 ,\n",
              "                0.6609434 , -0.88924336],\n",
              "              [ 0.67692804, -1.1559732 , -0.19193281, ..., -1.2533475 ,\n",
              "                0.66945153, -0.91397405],\n",
              "              [ 0.70763206, -1.1560674 , -0.2756779 , ..., -1.2750483 ,\n",
              "                0.719731  , -0.8506348 ],\n",
              "              ...,\n",
              "              [-0.9028443 ,  1.044466  ,  0.417493  , ...,  1.2237705 ,\n",
              "               -0.8559852 ,  0.77337176],\n",
              "              [-0.8659889 ,  1.0475663 ,  0.3960921 , ...,  1.2278892 ,\n",
              "               -0.86807036,  0.73629713],\n",
              "              [-0.8832729 ,  1.0409284 ,  0.39708826, ...,  1.2213017 ,\n",
              "               -0.8686504 ,  0.75241935]],\n",
              "\n",
              "             ...,\n",
              "\n",
              "             [[ 0.8144755 , -1.0860397 , -0.3082708 , ..., -1.2290646 ,\n",
              "                0.7494857 , -0.856706  ],\n",
              "              [ 0.8354527 , -1.1035005 , -0.3942834 , ..., -1.2489858 ,\n",
              "                0.7857519 , -0.7998355 ],\n",
              "              [ 0.8335105 , -1.0889639 , -0.34801683, ..., -1.2360317 ,\n",
              "                0.7464802 , -0.85050035],\n",
              "              ...,\n",
              "              [-0.9742213 ,  0.99323946,  0.30015835, ...,  1.1165289 ,\n",
              "               -0.7540555 ,  0.94312984],\n",
              "              [ 0.8419894 , -1.0556585 , -0.28980988, ..., -1.2018135 ,\n",
              "                0.7612512 , -0.86465514],\n",
              "              [-0.909755  ,  0.96292317,  0.07300005, ...,  1.030578  ,\n",
              "               -0.6166704 ,  1.0975006 ]],\n",
              "\n",
              "             [[ 0.6820896 , -1.142348  , -0.21523307, ..., -1.2361375 ,\n",
              "                0.85975784, -0.7852618 ],\n",
              "              [-0.78740555,  1.085316  ,  0.36569333, ...,  1.2547505 ,\n",
              "               -0.83006126,  0.7196638 ],\n",
              "              [-0.92075056,  1.079048  ,  0.53432435, ...,  1.25573   ,\n",
              "               -0.8130687 ,  0.746183  ],\n",
              "              ...,\n",
              "              [-0.8565994 ,  1.1005057 ,  0.48832598, ...,  1.2708396 ,\n",
              "               -0.8034706 ,  0.732224  ],\n",
              "              [-0.87043786,  1.0520198 ,  0.3964416 , ...,  1.2288551 ,\n",
              "               -0.8427248 ,  0.7607371 ],\n",
              "              [-0.79132366,  1.0826106 ,  0.3609904 , ...,  1.252331  ,\n",
              "               -0.82865536,  0.72807354]],\n",
              "\n",
              "             [[ 0.8339335 , -1.0510732 , -0.3113187 , ..., -1.2303994 ,\n",
              "                0.7995722 , -0.8335007 ],\n",
              "              [ 0.8298403 , -1.0592809 , -0.31267756, ..., -1.2349359 ,\n",
              "                0.7909504 , -0.8417046 ],\n",
              "              [ 0.85465586, -1.0718495 , -0.36612993, ..., -1.2443761 ,\n",
              "                0.77954763, -0.8440586 ],\n",
              "              ...,\n",
              "              [-0.62165374,  1.1764381 ,  0.06661539, ...,  1.185097  ,\n",
              "               -0.39629272,  1.0919832 ],\n",
              "              [ 0.90283155, -1.1054996 , -0.61631256, ..., -1.3063196 ,\n",
              "                0.864921  , -0.6820605 ],\n",
              "              [-0.61341006,  1.1802839 ,  0.06870057, ...,  1.1912264 ,\n",
              "               -0.41115323,  1.0747586 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.init(random.PRNGKey(0), example_x, example_y).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6p52-tsCMsa",
        "outputId": "954d1336-9afb-4f9b-9de7-fb500c52f1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "frozen_dict_keys(['params'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training functions"
      ],
      "metadata": {
        "id": "1KgaDv1QJNWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from optax._src.base import Updates\n",
        "\n",
        "def predict_logits(params, input_sequences):\n",
        "  # TODO: The second input parameter should not be input_sequences\n",
        "  return transformer.apply({'params': params}, input_sequences, input_sequences)\n",
        "\n",
        "\n",
        "def loss_and_accuracy(params, input_sequences, targets):\n",
        "  \"\"\"Computes ce loss.\"\"\"\n",
        "  logits = predict_logits(params, input_sequences)\n",
        "  vocab_size = logits.shape[-1]\n",
        "  target_onehot = jax.nn.one_hot(n_targets, num_classes=vocab_size)\n",
        "  loss = optax.softmax_cross_entropy(logits, target_onehot).mean()\n",
        "  accuracy = (logits.argmax(axis=-1) == targets).astype(jnp.float32).mean()\n",
        "  return loss, accuracy\n",
        "\n",
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  _, targets = batch\n",
        "  input_sequences = batch_to_input(batch)\n",
        "  # Calculate loss value and its gradients by the value_and_grad function\n",
        "  loss_fn = lambda params: loss_and_accuracy(params, input_sequences, targets)\n",
        "  ret, grads = jax.value_and_grad(\n",
        "      loss_fn,\n",
        "      has_aux=True)(params)\n",
        "  loss, acc = ret[0], ret[1]\n",
        "  # Update the parameters\n",
        "  updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state, loss, acc\n",
        "\n",
        "def batch_to_input(batch):\n",
        "  inp_data, _ = batch\n",
        "  # There are 10 digits (0, 1, ..., 9) and therefore when we make the \"embedding\",\n",
        "  # num_classes is 10.\n",
        "  inp_data = jax.nn.one_hot(inp_data, num_classes=10)\n",
        "  return inp_data\n",
        "\n",
        "def train_epoch(train_loader, epoch_idx: int, opt_state, params):\n",
        "  accs, losses = [], []\n",
        "  for batch in train_loader:\n",
        "    params, opt_state, loss, accuracy = train_step(params, opt_state, batch)\n",
        "    losses.append(loss)\n",
        "    accs.append(accuracy)\n",
        "  avg_loss = np.stack(jax.device_get(losses)).mean()\n",
        "  avg_acc = np.stack(jax.device_get(accs)).mean()\n",
        "\n",
        "def train_model(train_loader, val_loader, opt_state, params, num_epochs: int = 2):\n",
        "  # Train model for defined number of epochs\n",
        "  # best_acc = 0.0\n",
        "  for epoch_idx in range(1, num_epochs+1):\n",
        "    train_epoch(train_loader, epoch_idx=epoch_idx, opt_state=opt_state,\n",
        "                params=params)\n",
        "    # if epoch_idx % 5 == 0:\n",
        "    #   eval_acc = eval_model(val_loader)\n",
        "    #   logger.add_scalar('val/accuracy', eval_acc, global_step=epoch_idx)\n",
        "    #   if eval_acc >= best_acc:\n",
        "    #     best_acc = eval_acc\n",
        "    #     save_model(step=epoch_idx)\n",
        "    #   self.logger.flush()"
      ],
      "metadata": {
        "id": "uXA8469HB-lX",
        "outputId": "6d70f798-cb0e-4898-d928-f9cf9d095850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ab1936bfec7>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'jax' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the dataset"
      ],
      "metadata": {
        "id": "IgeEccMNsD0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1 Reversed Sequence"
      ],
      "metadata": {
        "id": "ls6UBvG4z-Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a map-style PyTorch dataset\n",
        "# (see more documentation at https://pytorch.org/docs/stable/data.html)\n",
        "class ReverseDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_categories: int,\n",
        "                 seq_len: int,\n",
        "                 size: int,\n",
        "                 np_rng: ...):\n",
        "        super().__init__()\n",
        "        self.num_categories = num_categories\n",
        "        self.seq_len = seq_len\n",
        "        self.size = size\n",
        "        self.np_rng = np_rng\n",
        "\n",
        "        self.data = self.np_rng.integers(self.num_categories, size=(self.size, self.seq_len))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_data = self.data[idx]\n",
        "        labels = np.flip(input_data, axis=0)\n",
        "        return input_data, labels"
      ],
      "metadata": {
        "id": "XxyAITGp0E6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine batch elements (all numpy) by stacking\n",
        "def numpy_collate(batch):\n",
        "    if isinstance(batch[0], np.ndarray):\n",
        "        return np.stack(batch)\n",
        "    elif isinstance(batch[0], (tuple,list)):\n",
        "        transposed = zip(*batch)\n",
        "        return [numpy_collate(samples) for samples in transposed]\n",
        "    else:\n",
        "        return np.array(batch)\n",
        "\n",
        "dataset = partial(ReverseDataset, 20, 10)\n",
        "rev_train_loader = data.DataLoader(dataset(50000, np_rng=np.random.default_rng(42)),\n",
        "                                   batch_size=64,\n",
        "                                   shuffle=True,\n",
        "                                   drop_last=True,\n",
        "                                   collate_fn=numpy_collate)\n",
        "rev_val_loader   = data.DataLoader(dataset(1000, np_rng=np.random.default_rng(43)),\n",
        "                                   batch_size=64,\n",
        "                                   collate_fn=numpy_collate)\n",
        "rev_test_loader  = data.DataLoader(dataset(10000, np_rng=np.random.default_rng(44)),\n",
        "                                   batch_size=64,\n",
        "                                   collate_fn=numpy_collate)"
      ],
      "metadata": {
        "id": "pVBKoe0u0kq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_data, labels = rev_train_loader.dataset[0]\n",
        "print(\"Input data:\", inp_data)\n",
        "print(\"Labels:    \", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80NBJEFoBesV",
        "outputId": "cf3a3093-10a3-4990-f655-019078386043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data: [ 1 15 13  8  8 17  1 13  4  1]\n",
            "Labels:     [ 1  4 13  1 17  8  8 13 15  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "YZClm5QxzvpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "1rSMArI8FrBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optax.adam(learning_rate=1e-2)"
      ],
      "metadata": {
        "id": "SsXcqtJz2m5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_state = optimizer.init(params)"
      ],
      "metadata": {
        "id": "3FBhnZpeH1rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(rev_train_loader, rev_val_loader, params=params, opt_state=opt_state)"
      ],
      "metadata": {
        "id": "ZxCJe5PCKfJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3N0ubHn_DjA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}